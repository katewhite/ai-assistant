Fall 2025

>>Hannah Patterson	00:00
I think we've got everybody. Cool. How's everybody doing on this Wednesday morning, afternoon? People are kind of tired. Yeah, tired? Busy week? It's really cold here. Is it? Like the like first few days that it's cold in Denver. I'm like, why do I live here? Like, is this the right spot?

>>Emily Brown	00:28
How cold is it?

>>Hannah Patterson	00:31
It was like 25 Fahrenheit when I was walking to work this morning. Yeah.

>>Emily Brown	00:36
Yeah.

>>Hannah Patterson	00:37
I mean, it's supposed to get up to like 65. So.

>>Emily Brown	00:41
That's also crazy.

>>Hannah Patterson	00:43
Yeah.

>>Kate White	00:44
This is why I'm sitting in front of the fire this morning instead of in my office.

>>Hannah Patterson	00:50
This time of year is so tough because I also feel ridiculous wearing like a parka to work when it's going to be 65 on my walk home. So.

>>Craig Phillips	00:59
Well, well, our clocks just our clocks changed last week. So the sun now sets at like 515. Yeah. So our dark winter is upon us.

>>Hannah Patterson	01:10
We'll be with you this weekend.

>>Craig Phillips	01:15
Oh, right. Fantastic. All right. Well, this session, we have Emily leading the discussion. Thanks, Emily, for doing this. Yeah, I think we can take this in a number of ways, but I think like the general thought was, you know, Emily, since you've been so close to data, especially around first time Ux, but also like just more broadly about sort of usage data that you could kind of walk us through. Maybe some of the big insights you've had, some of the things you've learned and just kind of like a tour of maybe what what you've looked at, what you've what you've discovered. And then maybe we can just kind of pick your brain a bit on a few topics.

>>Emily Brown	02:01
Cool. I started putting together like a notion doc. This is mostly like business business metrics. So I I'm going to start by walking through these, but then we can move on to other metrics as you like, or I can provide reference materials or like links to Tableau dashboards, etc. But also, please ask me questions as I go. Like, just interrupt me. Do not be shy, because I think talking about some of this stuff could be very, very dry unless we we have a discussion about it. Cool. Okay, so the first couple things that I pulled in, put in the notion doc, I actually pulled out from the Q3 board materials. This guy is showing a graph of the monthly net dollar retention for each month. And Ltm, this is what would be like, I think the average. And then this is the prior year's Ltm. I won't get into like, what, what that all means. Clearly, Ben made this slide. But what we're like, the key message here is really that, oh, sorry, and it's gross retention and net retention. So gross on a gross retention basis, right now we're at 89, 90 % kind of average monthly gross customer retention. And on a net retention basis, I'm looking at the orange here, we're at like a 95 to 97 .5 % net dollar retention.

>>Emily Brown	03:49
So just my reflection when I look at these numbers, is that they are low compared to where we want to be. Both the gross customer retention is low and the net dollar retention. Is low. So gross customer retention. This is essentially gross dollar gross customer retention is like, basically is the same thing. Your ceiling is always 100. So the best you can ever do is 100. And it's how much you're, how many as a percentage of customers or logos, you're retaining month over month. So we would want to be somewhere in the 90s here in order for this to be like a quote, unquote, good metric. And this, this just shows that we're having more customers are churning each month than we would want to have ideally. On the net retention chart, the one below that, there is not a 100 % ceiling. So you can go above 100 through upsells in particular, the way the math is done.

>>Emily Brown	04:58
Calculated. You can go really deep into like net dollar retention math, but here our main mechanism for upsells for net dollar retention is upsells. I can't remember if reactivations are in the net dollar retention number. They might be rather than netted against the chart. So I would say definitely upsells, potentially reactivation to get you above 100. We would definitely want to be above a hundred here. So the fact that this is below a hundred is not great because it just makes our entire kind of business model less efficient. You can really have a step change in growth if you are essentially able to expand your your the money that you make from customers over time rather than kind of trying always trying to fill a bucket, a somewhat leaky bucket. There's a whole thing about whether you calculate net dollar retention on like a quarterly or monthly basis or yearly basis and that impacts like where the the benchmark should be for these metrics. But the best companies, best SaaS companies would have monthly average net dollar retention in between 102 to 110, which would translate into like what you see the headline numbers are of these companies on a quarterly basis of like or yearly basis of like 140, 130 to 150 net dollar retention. Because if you retain it's like small bits above a hundred month by month translates to a lot of retention on a quarterly or in annual basis.

>>Emily Brown	06:47
Any questions on like I don't know how familiar folks are with like net dollar retention or gross dollar retention or like thinking about the mechanics of Saas businesses from like maybe like more the business metrics perspective.

>>Craig Phillips	07:07
I have one question just in terms of like do we have a specific target? Like is there a specific number that we're seeking or is it just sort of need it needs to be improved? Is that sort of where we're at?

>>Emily Brown	07:18
I think where we're at is that it needs to be improved. I don't think that we yet feel like we have the ability to move the toggles to know what a goal like a true goal would be.

>>Emily Brown	07:48
But I would say just looking at these numbers like a goal like a pretty reasonable goal would be to improve all of these by a 5 % not like 5 % improvement but like that 90 should be 95 and that 97 .6 should be 102 .6.

>>Craig Phillips	08:09
And I'm sure this will come in and other things But like I guess like the why behind this is that something that we're starting to get or are we still kind of completely in the dark? Yeah I

>>Emily Brown	08:20
Well I what I can show next is like that how these numbers kind of break down so you can start to then understand the trends underneath them which I think we'll get to the why. Any other questions before I move there? Nope Okay So the next one actually was in the board deck and I find this quite quite telling helpful. So this is breaking out that net retention number that we saw previously that was like 97 .6 at the at the end here between blue and plus which is the blue line and then core which is the orange No No No I'm doing it backwards. Core is the core is the blue line and plus and blue is the orange line. Unhelpful to have a color in one of the names and you can see here that the that the core folks on the core plan like our net dollar retention is still not really like at that goal so it's not at 102 .5 But it is significantly better than the plus net dollar retention.

>>Kate White	09:46
Okay But it sounds like because this is like surprising to me but it's because people are like bumping up and then downgrading and that that's what we're seeing.

>>Kate White	09:57
That dings the retention of the plus and blue, even if they're not like completely churning?

>>Emily Brown	10:02
So there are definitely some people, and they call that here, here kind of in the slide. Some people definitely upgrade from core to plus for a certain number of months to run X, Y, or Z test, and then they downgrade back to core. And so, yes, that is definitely a trend that exists within these numbers. There's another trend that we'll also see that people maybe start on blue or plus and just don't retain very well at all. So these numbers are a combination of people downgrading, potentially upgrading to blue or plus only for a set period of time, and then downgrading, and then a pretty poor early life cycle retention curve. On blue and plus.

>>Craig Phillips	11:00
And we capture, or at least we try to capture, I forget the term, but like the reasons that they've churned. So like, do we know like from the plus and blue, like, are they leaving because it wasn't the right plan for them? Because it, I mean, again, these are probably the details we'll get to later, but yeah, is it a price thing? Is it a functionality doesn't match the price? Is it, they're not getting the value that they think they could, or were they placed, were they advised to go there even though they shouldn't have been there in the first place, or I don't know.

>>Emily Brown	11:32
I think that that depends, probably depends a lot on like where they are in their life cycle and also the segment that they're in. So some of the work that Helen's been doing on like documenting self -serve churn and particularly self -serve blue and plus churns these are early life cycle self -serve blue and plus churn. It is very hard like to get properly activated on blue and plus as a self -serve merchant and can create like very complex situations where people are struggling to do that within the product themselves. Like the price integration process in particular to run a price test requires work from our team but then there are all sorts of other complications that can pop up relating to that. And then we have like can be a pretty complex process to resolve these issues for these merchants. And if they're like going back and forth with us kind of over tickets in pylon potentially touching many different teams, support teams or support people across the company. It can be a very kind of challenging process for them. And quite a lot of them churn not surprisingly many of them struggle to even get one test off the ground. So that's definitely a dynamic. We do struggle with early life cycle churn and like sales and partner led funnel merchants as well.

>>Emily Brown	13:17
Self -service definitely significantly worse than those two. But we do have a bit of a better like humans are more involved in the process from the outset to try and shepherd them through successfully. But that is definitely still a dynamic there. Sometimes there are a lot of complications around if someone has subscription prices or not or like potentially they can say very confidently that they want to test a certain thing when they come in and start talking to our sales team. And then like four weeks into the process they want to test something else. And that requires a lot of other work. And so we do struggle with that with those sorts of situations even in like a sales led process.

>>Emily Brown	14:18
I kind of alluded to this a little bit But I find it very helpful to think about and also to maybe orient you all as you're doing these listening tours and like talking to different members of the team to segment the customer base. And that is partly because Shopify has an extremely long tail. And so our customer base varies from extremely small merchants who are just getting started to very large well -established merchants with a lot of revenue and a lot of employees.

>>Emily Brown	14:56
And as a result, IntelliGEMS as a company has to take a segmented approach to our customer base, which means that, say, Gustavo, who you'll talk to, I think we'll talk to soon, Matt, who we talked to yesterday, they are, for the most part, really focused on the larger scale column here of segment of customers. And to some extent, the early scale, Gustavo will do integrations and onboardings for folks in here. Some AEs on Matt's team will do sales for some customers in here. But what's, I think, always important to call out is that that's like 30 % of our customer base in terms of logos. Our customers are like people on the team are actually like interacting with from a, not from a reactive support process, but from like a proactive sales onboarding and customer success process. It's not like fully clean like this, but that is a very much like in broad strokes. That's kind of the dynamic here. And so we on the product and design team have a challenge of really like wanting to think about all of the customers. And I think that's an important thing to think about.

>>Craig Phillips	16:26
Is there, I guess, tying this to the previous slide with the difference of the core plan versus the others. Is there also a, does that map here to like smaller growth stage or typically on core and they would never really be on the higher plans or?

>>Emily Brown	16:52
Ok, before I go to the Ndr and Gdr. No. So you can be on a you can choose no matter your size, you can choose whatever plan you want to be on. And so, like, as a if you're a merchant who signs up and you have 50 orders a month and you want to price test, you might choose to do our blue. Sorry, our plus plan. You will get minimal help from us if you choose to do that, except for the reactive support like pylon process. But we don't do anything that would prevent a merchant like that from getting on a plus plan if that's their like use case. They want to that they want to go after. I'm trying to think. I don't think there's really I think that the split between core and and plus pretty is pretty similarly split between all of the different segments. So there's not like a smaller segments like naturally gravity to core or not, at least the way the kind of the features match up to the plans today.

>>Emily Brown	18:13
Breaking down the net dollar retention between core and plus and then based upon the different customer segments, I also find to be pretty instructive. So. Kind of anchoring back to like that, that ninety seven point five percent overall net dollar retention, you can break that down even further. So if you look at core and you look at the net dollar retention by segment, you can see that we actually in our early scale and later scale segments like we're getting pretty close to our goal of over one hundred percent NDR. And where we're not meeting our goal would be in the growth segment where we're below one hundred percent. And then really the the non ICPs were well below. It larger companies just kind of inherently retain better and many of them, some of them will be signing long term contracts with us to begin with. So like there's we can't necessarily solve this problem by like just only serving the largest companies. And so by choosing to serve a wide variety and by not gating towards a certain customer size, we're always going to have this trend where larger companies have higher Ndr and customer retention versus the smaller companies. But the question would be, how can we kind of raise all of these and particularly areas that were underperforming? The for me, what's striking is that we are.

>>Emily Brown	19:55
Struggling on the Ndr basis for blue and plus across all different segments. You can see that in this bottom right column. The later scale is the closest to 100, but there's really quite a lot of gap here for early scale and the gross segments. And not at all surprised that the Ndr for non -ICP and blue and plus is so low. That's pretty far away from our Icp customers looking to do price tests, very small customers looking to do price tests in particular.

>>Craig Phillips	20:34
And non -ICP here, so is that like so small they're not even growth? Is that true?

>>Emily Brown	20:40
This is, yeah, so non -icp is this column over here. This is folks that are doing less than 500 orders per month. So we kind of pick that metric because we would say we have this like very high level idea that you have to have 600 orders in total or 300 orders per test group in order to get to some sort of reasonable understanding of a test being having meaningful results. And so if you are testing across your entire order base and running that test for a month and you're not achieving that just because you don't have enough orders, it's really hard for us to say that we have a valuable product to sell to you, at least in the like very testing focused way of thinking about the IntelliGEMS product. But just an important thing to call out is that that's 20 % of our customer logos are this non -ICP segment, much less in terms of revenue, like 9 to 10 % in terms of revenue, but 20 % of logos.

>>Emily Brown	22:07
I'm going to maybe move down here where this is another slide from the board deck. Basically one of the key components of the Ndr and Gdr kind of metrics and one of the reasons why the numbers are lower than we would want them to be is due to early life cycle churn and net dollar retention trends. So what this chart is basically showing is that in the first quarter, all of these are sloping down. These are all different cohorts of new customers over time. But once that they hit that kind of initial slope down, then the customers who remain tend to be fairly lead to a fairly steady retention curve. It's not surprising that there would be some early life cycle churn. I think it would be not achievable to only have to have no churn early in customer life cycle, but this is pretty striking in the slope and then kind of the, I don't know, plateau here. And so one of the areas that we feel like we can focus on is kind of making this slope less steep and trying to minimize early life cycle churn.

>>Emily Brown	23:51
And then there's another challenge, which is we don't have a lot of mechanisms by which to consistently then grow customers over time, particularly if kind of going to the plateau over here on the right side of the charts. So like, if our biggest way of kind of getting folks to pay more is to do, to upgrade to plus, but then they're only upgrading to plus for a couple months and then downgrading again, that kind of gets us just kind of netting out back to this, to this one level. I mean, it's good that we're like this later on in life cycle and not going down, but it would be great to have mechanisms by which this could actually start to go up.

>>Emily Brown	24:43
And then the last one on this is one thing that I was doing a couple of weeks ago was really

>>Emily Brown	24:54
Diving into tracking net dollar retention and gross dollar retention or logo retention on a weekly cohort basis by each week of new installs. I have a dashboard that kind of tracks this, and we've started looking at pretty consistently. But that kind of starts to get into this like slope of the curve dynamic. This is looking at week five after a customer becomes a paying customer. What's their Ndr? And then week 10 after they become a paying customer, what is their Ndr in core versus plus? Can see like this drop off for growth in early scale by week five, and then starts to kind of like steady out by week 10. Later scale is retaining very well, which is great. But then in week five in plus and blue, you can see that it's very stark, the decline, and then continues to decline by week 10.

>>Emily Brown	26:20
So I guess maybe all of this. Yeah, go ahead.

>>Craig Phillips	26:22
Yeah, no, just on time, I want to make sure. So we're almost at the hour mark, or that 30 -minute mark. I'm good to keep going if others, if you are Emily, if anybody else is free. I just wanted to call out the time in case it was an issue.

>>Emily Brown	26:42
I don't have many more pieces of data that I've prepared. I think maybe the learning is that focusing on early life cycle, like the learning and the bet is that focusing on early life cycle could be a very important lever to improving gross customer retention and net dollar retention. And so that's kind of like the focus and one of the levers that we want to pull and see that can then actually play out. And then maybe how that translates to all of us is that the way to do that from a product perspective is to get people up and using and finding value from the product consistently. As quickly as possible in their life cycle. And so the bet is if we focus on that and if we meaningfully improve those metrics, so meaningfully improve how many people successfully install our script, which is like the baseline level that they need to do to get value out of our product. If we can meaningfully improve the number of folks who do that and the time for them to do that. And then from there, if we can meaningfully improve the number of folks who are successfully launching a test and get them to successfully launch a test or experience extremely quickly in their life cycle, that will get them up and seeing value faster.

>>Emily Brown	28:26
Then can we get the, if we can, once we've caught past those two hurdles, can we get them to do a second one and a third one, et cetera, et cetera. And so that's kind of, that's our focus and our bet and where we're starting to chip away at these.

>>Craig Phillips	28:45
That's, yeah, that was going to be, Yeah, I think that specificity is really good. I wonder, is there anything even more, even if it's not grounded in data, but maybe even just intuition from everybody here? Is there more specificity in terms of what to activate on, just given there's so many, within testing experiences, there's so many routes they could take? I don't know if there's any, because sometimes we do we lean into the easier tests because the content test maybe could be created and launched relatively easily, but does that actually impact the longer trail there? Or should the focus be on something different, like should it be on making price tests easier for people in those tiers that have that?

>>Emily Brown	29:36
I don't know.

>>Craig Phillips	29:37
Is there any, I'd be curious if there's any specificity that has come up around where we prioritize that. If that makes sense.

>>Emily Brown	29:52
I have no idea.

>>Emily Brown	29:53
Thoughts, but I'm curious what other people maybe to hear from others.

>>Angela Wang	30:00
Something that I've noticed in these two listening sessions is that price tests keep coming up as a pretty big issue.

>>Kate White	30:09
So I'm immediately thinking of that first, but I don't know if it this is where I'm curious on Emily's opinion, but if it's truly just about speed, then the easy ones make sense, like get them in that reward loop, if you will, of like, whoa, testing does make an impact on my profit as quickly as possible, regardless of which test it is. But if we truly believe our differentiating and what we want to be, and I think this is part of what we want, like one of the outcomes of this whole exercise to be, but if price testing is our core, then that would put a different spin on what we push for first. Little chicken and egg is what I just did there, but so I don't know the answer.

>>Angela Wang	31:11
Didn't Matt say yesterday something about like basically our price testing being like our secret sauce that like our competitors can't actually do even though they say they can do? So also just thinking about that as well.

>>Hannah Patterson	31:30
I think it could also depend a bit on the brand, like I don't know that it's necessarily a one -size -fits -all Answer, because like price testing, for example, if a store has a handful of products, I think price testing can be worse to push them into because they just don't have as much runway on like what they can test there, where if a brand has like a ton of different product lines, a ton of different options on testing there, I think that makes more sense. So Yeah, I just don't know that it's like a one -size -fits -all, which makes things harder, but maybe we need to be a little bit more personalized.

>>Kate White	32:07
Yeah, that's a really good point. I think you're spot on there. It's where they're going to see the most value and yes, most quickly.

>>Hannah Patterson	32:17
Yeah.

>>Angel Austin	32:18
It makes me wonder the personas that really thrive in each plan and if it is different between the few that we're focusing on, noticing that there isn't as deep of a retention issue with like core, it also makes me wonder with plus if there's a price sensitivity, like you're literally thinking about pricing, you're thinking about experimentation And so Yeah, I wonder if with content just being significantly less expensive, they feel more creative and able to just test more things, whereas like the price point might be a little bit too high for them to feel like they can continue to just play. It also made me think that maybe there could be a fun pathway for the folks that are in core and core redirect to maybe we give them one price test for free after so many months to help get them into an upgrade path, but Yeah, I just see the data is so different on retention at least. It's just interesting.

>>Emily Brown	33:33
One of the things that you hit on there, Angel, is that content testing as it relates to Cro is someone's jobs to be done, particularly as you move into the early scale and later scale segments. Someone had like in their job description, it will say something about testing their site to improve conversion. Then it's like, okay, well, which tool are we going to use? Some of them will choose to use us. Some of them will choose to use Shoplift or Visually or some other tool, but it's like kind of a thing. There is no one right now, like their job descriptions does not say like their job is to test prices. There isn't really a persona tied to that. That's one of the challenges and opportunities.

>>Emily Brown	34:35
For me, I do wonder if we have like a pricing and packaging. We should be thinking more about pricing and packaging. Something like checkout blocks that's mostly stores who are on Shopify Plus. I do wonder if like that entire

>>Emily Brown	34:52
Thing, like kind of product offering should be on our plus plan because there's like a ability to pay if you're paying for Shopify plus already you probably have a much higher ability to pay versus maybe offer testing should be on core and we drive people to start testing for profitability on a lower price plan through something like offers. I don't know that's just like a question that I have in my mind and also how can we maybe not tie plus and price testing so tightly together that like you're really moving to plus to price test can you can you move to plus to do other things. I know we try have tried to do that with having shipping and offer testing But so far I think maybe struggling with that a bit.

>>Kate White	35:46
Yeah I know it's not a huge part of what we're exploring next week But I've been thinking the same thing like not to open a can of worms But I feel like if we say our core value is testing and that's what we're known for but you can't do that unless you're on one of the higher plans is a little odd to me and that bouncing back and forth between plans seems like a pretty clear indicator that that's not working for people. I personally And I haven't done enough research here this is a gut feel I personally believe in giving people a taste of your core value and when they've been sold then their motivation and desire to upgrade should be possible and it should be based on you know frequency of tests or volume of tests or some other sort of like growth mechanism rather than like oh you have to upgrade to even understand the core value of our product. So yeah all that say I agree.

>>Emily Brown	36:57
Going back to your initial question Craig I do think that we could get better at being getting knowing which items things we want people to activate immediately that they'll see value from and that might not be the same thing for every install it might be different But I do think that we can be stronger in like pushing for very specific things that we know people can do more successfully and faster sooner and that might not be price testing.

>>Craig Phillips	37:29
Yeah.

>>Emily Brown	37:30
A large number. Yeah.

>>Craig Phillips	37:32
Yeah and kind of like to Angel's point about personas but even maybe from another angle like is it like what is maybe we already think about it this way But like what is what's the priority activation for core what's the priority activation for plus what's for blue like So if somebody's in this plan this is the this is the this is what we're trying to activate them on and maybe it's is it you know to what extent and like what's the most important thing And then how do we make that as easy as possible like to you said like how do we get them to launch the thing how do we get them to like how to faster I guess the faster time to launch or whatever But then it's sort of looked at through the lens of the plans which I don't know because plans change and the way we package those up could could be different in a couple months But I guess it's one another way to think about it I think that partly I'm telling myself because I often think about like how do we activate on the most and the easiest thing or like give the recommendations for the the simple stuff that you can like a one -click test kind of experience But you know if they're there for something completely different and they may be specified in onboarding that they want they're here for let's say they're here for price testing so then how do we invest in the price test you know as making that easier and will that give us more overall lift as opposed to you know an Ai assisted content test you know whatever which might not give us as much bang for the buck but just reminds me did we decide on which metrics were focused on or obviously churn and retention but was there a theme or are we just kind of focusing on our lanes as as partners for the purpose of this print

>>Craig Phillips	39:31
I mean Yeah Like we're kind of general Right what did we write we wrote we wrote yeah There's a whole list of them reduced I mean churn is churn and activation I guess would be the relevant ones here Yeah

>>Craig Phillips	39:52
Okay. Yeah, I mean, there's other things in there, but I guess in terms of like the related metrics, I don't think we have specific numbers, and I don't think we should. I think it would be too specific and it wouldn't even really be meaningful. But yeah, to make sure those things are front of mind. Kind of closely related is the self -serve. I mean, Emily, you mentioned self -serve in there, and to what extent that comes into play. There's obviously ways we design for that, whether that's related to the install or the theme install flow, things around that. Or is there anything we can do with the price integration? I don't know in the weeds enough to really say, but I think probably some of you know that much better. But yeah, how much, how that self -serve process could then facilitate it, even if it is hard to set up. Could we do more?

>>Emily Brown	40:55
I know Hannah's going to talk about the competitors and like different flows that they have. But one that folks were talking about yesterday, just on a couple of sessions that I had was, I can't, is it AB something, Hannah? I can't remember. The one where you essentially start to set up a price test, and then they be like, we're going to check this with our team overnight. And then they probably do the integration, kind of like Wizard of Oz it. And so that might be something for some of us to explore, of how can we manage expectations ahead of time that you're not going to get this price test up and running in the next five minutes. But you get them started and have them start, feel invested, but then do the things that we need to do behind the scenes.

>>Hannah Patterson	41:51
There's two that are like that. I think it's absolutely, and someone else. I have mixed feelings on it. I don't know. There's just so many things with price testing that people don't think about. There's other currencies, there's subscriptions, there's bundles, there's other third -party apps. I'm not going to die on this hill, but I don't think price testing is a self -serve product. I just don't think it's too complex. There's such a slim set of the market that's ever going to be able to come in, set up a price test, tag their own prices, and get it started. But I think the value we get from putting more effort into that just isn't worth the squeeze. I'd love to be proved wrong on it. I just don't know that I will be.

>>Craig Phillips	42:39
If that's just the nature of the thing, you don't know better than me. Do we invest in the human -supported process of getting those set up? I don't know enough about how that happens today. Is it through your customer success rep that they are there to do that? That used to be a big chunk of your job, right, Hannah?

>>Hannah Patterson	43:03
Yeah.

>>Craig Phillips	43:06
If we're trying to move that metrics in the right way, maybe a self -serve product is not going to be the solution, but maybe a person to then guide. That won't scale great, but it may improve the numbers. I don't know.

>>Hannah Patterson	43:21
Yeah. Something like you set up a price test, you immediately book a kickoff call, you don't have to go through sales, you just book a kickoff call. Between them booking the kickoff call and the call actually happening, we do the integration. The only thing is then all those things can still come into play. It could be we figure out they have subscriptions, which means we might need to use duplicate products, which then we need to make sure they're okay with that. Just a lot of branches in the way that it can go from there. Mm -hmm.

>>Emily Brown	43:53
One thing we were kicking around yesterday was maybe doing an actual, almost install flow for price testing specifically. Going through steps of, do you have subscription products? We've noticed this in your, can you confirm this? Going back and forth, what could we potentially do to facilitate or assist the human process in some way?

>>Angela Wang	44:27
It would be so great if we had Ai smart enough to detect these things and tell them what they have up front as well, but I don't think that's possible.

>>Craig Phillips	44:40
I wonder what site, as site wide comes in, as we start, we can read product catalogs, I'm sure there's enough that we could determine.

>>Craig Phillips	44:50
At least like hit on those main points and see like, are you ready? Are you set up for this? And then book the call or whatever, you know.

>>Hannah Patterson	44:59
I think those types of questions would be good too because I think a lot of times customers just don't even think about that stuff making price testing more complex. They just think this is price testing. I sell a product, I can do it. So yeah, like asking some of those questions to make them realize how much more complex that can make it.

>>Emily Brown	45:21
Some of these things we definitely can tell, like knowing if someone has been selling subscription products, that's like an extremely easy thing that we should be able to, can tell like almost immediately when we start to get their data. Like which apps they're using, I think it's like, gets a little murky. Like there's some stuff, but like gets a little murkier, but like I'm sure we could do something here.

>>Hannah Patterson	45:47
Yeah, I'd be interested with like how many false positives we get. I think with subscriptions, we'd get a lot where like they have this one random product that they have set up with a selling plan, but they're never actually gonna price test that product. I don't know how high of a percentage it would be, but I'd be curious.

>>Craig Phillips	46:15
That's tough. All right. Well, for anybody who's joining the next session, we're talking with Gustavo in a few minutes, but everybody might want a few minute break. Sure, we could talk about this all day. That's it. Was there any final notes or final questions or anything before we wrap it up? Anyway, we know where to find each other if we do. So, all right, well, thank you Emily. Thanks so much for putting us together.

>>Emily Brown	46:49
Thanks guys. All right, take care. Bye.