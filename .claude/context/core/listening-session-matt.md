Fall 2025

>>Kate White	00:00
All right, everybody's doing today and I'm watching all of your onboarding competitor Walk through looms. Finally. I've had reminders that Anyway, do you have those like stored anywhere?

>>Hannah Patterson	00:25
I was gonna dump them in the competitor library that I think is mostly just mine at the moment, but I have them in a notion doc, but definitely down to get them into like a Probably worth putting them into like a public folder Okay, cool.

>>Kate White	00:46
Yeah, they're really really helpful. I threw him here again, I don't know if this is a thing that in fact, I know it's not something that has been widely adopted by the product design team yet, but Anyway, I it helps me so Feel free to leverage this anyone if you want. I just threw it in product design kill Sweet

>>Hannah Patterson	01:22
I can throw my Stuff in there, too. The other thing I did that has been helpful is I like added granola while I was doing the looms And so then it also like gave me pros and cons and that type of stuff, which was nice So I can hear those in there too.

>>Kate White	01:40
Love it. Yeah, feel free. I just like dumped your looms in there I tagged them onboarding although in some of them. I know you went through like shipping test and then check out.

>>Craig Phillips	01:48
I also put them As shipping and check out test Anyway, if anyone has recommendations on a better way to organize this or whatever I'm open to it, but I just kind of like having like a place where we can Dump all the competitive insights It's on his way, so there's a notion there Just look like the core questions we were thinking to get out of this Might be a lot to get through but we'll see What we can

>>Emily Brown	05:08
Hey guys, Matt and I are in the same room. He's just trying to join. We're in the Internet's really really slow Yeah, you were super pixelated No words All right.

>>Craig Phillips	05:46
How's the how's The New York Internet?

>>Craig Phillips	05:57
Thank you for your patience, yeah, and we're all connected it's not too much delay. Thank you.

>>Emily Brown	06:04
Yes Cool looking forward to this conversation.

>>Craig Phillips	06:10
Yeah, thanks for Thanks for jumping in. So, um Yeah, so I mean, I don't wanna go too much background waste time but basically we're kicking off a bit of a bit of a sprint to kind of evaluate some of our Core product flows and then sort of like core product issues that we want to maybe try to try to solve with some some redesign work So we're doing a bit of a listening tour to just get a lot more perspectives in so obviously interested in your take I'm assuming you can hear me And you just turned off the Camera to preserve bandwidth Yes.

>>Emily Brown	06:44
Yes. You're still here.

>>Craig Phillips	06:45
So Yeah, so we had some questions for you I just wanted to like, you know get your take on a few angles But really just to bring in kind of this sales perspective into our thinking obviously, we're thinking, you know all in the realm of product, but Yeah, so I do have like a few Do you still see the the notion link in the chat? Is that still there or do I have to resend?

>>Emily Brown	07:10
Let's see Please resend it.

>>Craig Phillips	07:16
Okay, so see if that opens up Got it that works here. Yeah, cool. So so these are kind of the high level Yeah, we were we were looking to dig into you So like, you know We can take it if any of them jump out to you is particularly like something you could speak to But sure you can speak to all of them, but Yeah, we can also just go through through each one and anything like any other background Matt for for you that that will be helpful No, I think I can I can dive right into it it

>>Emily Brown	07:55
And you can let me know how relevant or not relevant this is But It feels to me like we have Three different categories of customer scenarios Related to their Testing sophistication interest and motivation And I would put them into into three buckets bucket one Or you know one one bucket are the customers that come in saying I Literally don't even know where to start Testing But I feel like I should Or I would like to Another bucket are customers that come in with one in mind And They're pretty adamant about the fact that either they don't know or they don't want Or they don't have much interest in testing beyond that one or two test idea And then category number three are the folks that Have a sophisticated Testing capacity. They have a roadmap built and they're just looking for a tool to better serve them if it feels to me like the bucket in the middle of the folks that come in with like one or two specific tests in mind are The ones that cause us the most pain Whether you know mostly due to like onboarding resources or not and just their general retention with us That third bucket of the folks that come in with like a really sophisticated Roadmap already they sign up for an annual plan like those folks are are most likely to be the ones that cause us the most pain

>>Emily Brown	09:53
Mostly good to go, barring technical integration -related issues, which is kind of a different topic. But those first two buckets of folks that come in not knowing what even to test first and are looking for more continuous ideas, and the second bucket of folks that come in with one or two specific test ideas and either are adamant about stopping there or would continue if they had other ideas, those feel like the biggest opportunities for us in terms of the customer conversations we have every day and this goal of signing people up at a high clip and also supporting their continued use of the tool. It's this idea of folks running out of ideas to test them. They're just not testing as much as we want them to. I have this vision in my mind of this golden state of the product and pitch that I think would be incredibly impactful. And again, you can let me know how helpful or unhelpful this is. But I see this world in which we are able to communicate and customers are able to experience a scenario in which they install the app. They leverage site -wide analytics in such a way that we are able to call out specific metrics on their site that fall below benchmarks for their industry size, shape, et cetera to say, hey, objectively, these key metrics on your site are below your competitors.

>>Emily Brown	11:39
Step one. Step two. We have some way of not just sharing high -level examples of what they can experiment with to improve those metrics. That's probably step two. And then evolution number three is quite literally some way, shape, or form of building and or showing them exactly what those experiments would look like on their site in particular. And then maybe even step four is us actually in some automated way building and launching those experiments for them. But in terms of viewing one of the largest opportunities for the business being retention and assuming retention is solved for by getting people to test more, it feels to me like leveraging site -wide analytics in that particular way can be a huge selling point for us in a variety of different ways. Even imagine a world in which site -wide analytics is available for free. That also becomes a huge lead generation tool where folks are able to access that data, get insight into opportunities that they have in their business, and then they take that next step to actually engage with us to solve for those things.

>>Emily Brown	13:28
That's one idea I have in my mind as it relates to the evolution of the product and our customers and retention as a whole. And then not to go too deep down this other rabbit hole, but the other piece that Emily, Alex, Sam, and I just got done talking through is really how we enable folks to successfully run price tests given the technical complexity of that solution. But I'd almost like, given those two things, it feels like number one, the first idea would go such a long way because it touches all aspects of experimentation, not just the price testing piece. I would love to be able to sell that, the first concept.

>>Craig Phillips	14:32
Yeah, in terms of coming from site -wide, analyzing the site, and providing the ideas for what could be done, showing them what that could look like, and then building that kind of core flow.

>>Emily Brown	14:47
Yeah, if I had that product, I would literally be building it.

>>Emily Brown	14:52
Entirely pitch from scratch. I think that can like totally change the direction, framing, positioning of like our business as a whole. Where like sure it's about experimentation, but you know I don't, we could go in so many different different directions with it. But it feels like one of the most common questions and concerns and hesitancies and doubts that I hear from customers is like what, literally the question, what should I test? What recommendations do you have? What examples do you have from other brands similar to me of like tests we should run? What are the most successful tests that you see? What are the tests that people are running right now? Like it's this Fomo thing. Is it all testing or is it also about personalized experiences or do people not ask you about personalized experiences? They do not. One percent of the time. I can literally think of one customer that I didn't even get on the phone that was like and they for whatever reason they didn't understand that we had you know the ability to like launch these experiences. But I don't know if I, I mean this sincerely, I don't in my year here, I don't know if I've had a single conversation that has started with the customer explaining their motivation for reaching out being personalizations and experiences.

>>Emily Brown	16:47
It's almost always experimentation And then I explain to them that they can then leverage our experiences to roll out winning experiences and that helps right sell them on the solution as a whole. But I think in a lot of ways if they were coming to us being like I'm looking for a tool to help me provide personalized experiences to customers, my question it assumes that they have confidence in what those experiences even are. So I would almost poke holes in that right away to help build the value of experimentation because that seems to be like the foundational core and most impactful value of our solution is helping them ensure that they are providing the right experiences to the right visitors. And I think that also speaks to kind of what I mentioned in the beginning where like the primary opportunity in our customers minds and the most prevalent mindset is one in which they are not certain of what to test.

>>Emily Brown	18:15
Again like there's obviously this whole other like category of like retention related to like technical integration and issues and etc etc like totally separate from that. This feels like the the highest leverage and most impactful concept for me.

>>Craig Phillips	18:41
Yeah, very cool. Can we dig in? I mean, I'm curious maybe building on this. I don't want to go well, we could go maybe more tactical but interested in like the demo process like the actual sales process. Are there are there key kind of objections or things that always come up as sticking points that we can't get over as like, you know, like core hurdles in like the foundation of the product that that that are common or I'm curious if anything comes up to your mind from related to that.

>>Emily Brown	19:16
I don't mean to like belabor the point. Um, there's there's two things. If someone is interested in price testing, currently, the biggest challenge is convincing them that they cannot do it anywhere else. Every other tool is saying that they can do it visually saying they can do it. Chocolate is saying they can do it. Um, and of course, those products are also much less expensive than our price testing package. So it'd be that that's it. That's

>>Emily Brown	19:51
That's a pretty difficult conversation to have because they need to trust the variety of pieces of information that we are giving to them before experiencing it themselves. And it's a very common phrase here. They're like, oh, they always come back. I don't want that. I want to win them the first time. I don't want to wait six months for them to have a crappy experience somewhere else and then come back. It feels like, as a business, we, I think I mentioned this in a different thread, but the Faq, our docs are a powerful tool because we explicitly call out price testing, where visually insured shoppers do not. So it's an easy thing for me to say. If they really did it that well, why is it not in their docs? That has helped us win a couple of those scenarios. And we've also lost a handful of scenarios where, for whatever reason, the prospect has decided to go with shoplift or visually roll the dice and try and make price testing work. It doesn't. Eventually, they maybe come back. But again, it just prolongs. That's not a good experience for anyone. So the objection or challenge in a sales conversation, number one is just really the ability to instill a degree of certainty in the prospect's mind that they cannot run this price test the way they want to anywhere else besides Intelligems before signing up and actually doing it. That's one. Number two, the same point as before, especially if price testing is not in the mix when it comes to a content testing comparison, Dev, Cinta, and Christos in our smaller business segment probably experience this way more than I have in the larger scale segment.

>>Emily Brown	21:57
But when I have encountered content testing, the content testing comparisons visually comes to mind in terms of their ability to provide recommendations. Apparently, they do that very well. The ease of use of the tool is very easy. A lot of drag and drop, a lot of no -code options for customizations, and their recommendations as a whole, that seems to land very well with folks considering visually. And shoplift on a content testing and content testing, it's just so much cheaper a lot of the time, where truly, if someone is just at the beginning. And again, this also lends itself to what we were talking about before. When folks are at the beginning of their testing journey, when they haven't done a lot of testing on their site, and they're like, listen, I haven't even gotten to level two, three, four, five, testing ideas, I literally just want to change a home page thing or run a single Pdp test. The phrase low -hanging fruit is often used of there's so much low -hanging fruit that we haven't even got to. Intelligence is so much more sophisticated. I just want to do this really simple test. And shoplift is half the cost. Why would I not just do that? Outside of the idea that why sign up for something now that you're eventually going to have to change when you do get to level two, three, four, if that doesn't land, then they probably go there. What causes them to, so I think I heard you say, if they want to specifically price test, they may go to one of these other tools that they physically can't.

>>Emily Brown	23:49
But what about the folks who maybe want to content test, and they start with shoplift, and then come back to intelligence? Why do they come? What drives them back? Two scenarios. One, sophistication within the content testing category. So Rise Mushroom Coffee was a good example where they were a couple of very specific examples that they brought up of things they couldn't do with shoplift in the content testing category was multivariate testing, running an AA test, and some degree of sophistication in regards to their analytics. So there are those points that we can call out, but again, those are very specific feature set things. And you have to be a sophisticated user to understand their value, or a somewhat sophisticated user to understand their value. Exactly. So I have seen customers come back to us in those areas.

>>Emily Brown	24:50
Scenarios where they literally just had trouble doing what they wanted to do from the content testing experience. And then pretty objectively is like, yo, sure, we've been running these like really basic content tests with Shoplift, but like we want to run a price test. And another reason why that is a less preferred customer journey is because now I have to get that customer's mindset from, I'm going to continue to use Shoplift, but just run this one price test with Intelligems to, okay, you're using Shoplift, you want to run a price test. Let's get you to stop using Shoplift as a whole and do everything with us. So it's a rip and replace situation versus just like making the decision to work with us from the job.

>>Craig Phillips	25:44
Good stuff. I'm curious, do you feel that it would be difficult for us to compete with Visually and Shoplift on the ease of use side? Like it sounds like from what you're saying, do we lean more into like the power and sophistication of what Intelligems can do?

>>Emily Brown	26:03
Yes.

>>Craig Phillips	26:03
Like come to us because we can do all the things and we can do them better, even if it's, maybe there's a bigger hurdle in terms of actually, yeah, like it's maybe less drag and drop and a few clicks And you're done, but there's a power there that you can't get elsewhere. Is that like a big part of the pitch?

>>Emily Brown	26:22
Yeah. A deal cycle, Revont, Revont Eyeglasses, perfect example of this. It was us against, they were on Shoplift and it was us against Visually. And like we had a whole, I had like, I can add you all to the little like Slack deal room I created, but there's like, it's word for word from the prospect there and literally in terms of how they were thinking about the comparison. And it is exactly that. It is like, they were literally weighing the cost benefit of the perception that like Visually is easier to use. They can do more quicker on a content testing side, but they would sacrifice sophistication and like the ability to price test or go with Intelligems and like have the sophistication be able to run price tests the way that they want, but they would sacrifice the ease of use on the content testing side. And like Kim and I have spoken about this and like our approach currently is to, we cannot go head to head on an ease of use. Like ease of use is not currently a value prop of Intelligems as it relates comparatively to those other tools.

>>Craig Phillips	27:41
All right. I know we're about at time. Do you have a hard stop, Matt, or do you need to?

>>Emily Brown	27:47
I do not.

>>Craig Phillips	27:49
Okay. Yeah. I'm curious. Anybody has any, anything's coming up in your heads that you want to use this moment for?

>>Angel Austin	28:00
Maybe during your pitch and this can be with anybody, not even just prospective clients, but do you find like statements or props that you use that are like consistently nodded along with that just resonate?

>>Emily Brown	28:14
Yeah. Kind of the, when I do my like standard IntelliGems intro and like deck part of the pitch and like, you know, if in a first call, like I'll use the first, you know, five to 10 minutes intros agenda, get an idea of like what they want to cover. Sometimes step two will be me diving into the actual deck itself to like lay down the foundation. Then I'll pop into the app, show them a couple of things and then use last five minutes to kind of wrap up. And it's usually like within that deck portion where those main bullet points of like the framing of Intelligems kind of happens. And the things I typically lean into are the fact that we are built for Shopify. And that's because there's like specific competitors that are not quote unquote built for Shopify and it's not visually Shopify. They are both Shopify, but who are the ones that are like that are beyond Shopify? Yeah. Vwo, Optimizely, Statsig, like any of those weird ones. But yes, as kind of a way of getting ahead of some of those objections, like the stamp, like especially in this market where there are so many tools, it feels like the number one question most folks need to have answered is what differentiates Intelligems. So I just.

>>Emily Brown	29:49
Just come right out and say it. And exactly to your point, I kind of put it in those two categories of like Google Intelligence is, you know, Shopify specific A -B testing and personalizations tool. We're focused on the idea of profitability, not just like top line revenue and performance. We do that through A -B testing and personalizations and the things that set us apart in the market. One, compares to any tool that is not built for Shopify, a ton of obvious benefits there, integration, I do say ease of use and compared to those like Bwo and Optimizely, 100 % were easier to use. And analytics, those are like main things I touch on compared to tools not built for Shopify. And that makes a ton of sense to people right away. And then category two is like, compares to any other tool that is built for Shopify, the things that are gonna differentiate us the most, the again, the depth and accuracy and breadth of analytics and also your testing options, where most tools just focus on top of funnel Cro and content testing. We also give brands the ability to test beyond the page, beyond what's typical, more profit oriented levers, things like product price points, shipping rates and offers. So like that's that initial foundation that is set that I feel helps folks frame and understand who we are. Beyond that, and then I'll touch on like the experiences piece before like wrapping up the deck portion. But it's really that kind of explanation of just like, we're gonna be easier to use and we'll have better analytics and all that stuff compared to anything not built for Shopify, compared to anything that is built for Shopify.

>>Emily Brown	31:42
We're gonna have better, more sophisticated analytics and we're gonna give you more things to test. And then the layer below that is compared to either of those categories. In addition to launching experiments, we also give our brands the ability to continue to take advantage of high performing experiments through the use of experiences. Nice.

>>Craig Phillips	32:11
Is the rollout of Sitewide, is that evolving the pitch as that starts to go out?

>>Emily Brown	32:19
It is specifically for, we like refer to them as, we are referring to them as our big rocks, where it's kind of like these outsiders day -to -day work kind of our main thematic strategic initiatives for a particular quarter. Alex in marketing has his, and in ops has hers. And for sales, the two big rocks for Q4, one is around like pipeline generation with higher value brands, and the other is kind of the X of the Intelligems pitch. So I'm currently working on that with Alex. I think Alex is gonna like deliver some, thematic options by the middle of November. And we plan to have the next evolution of the pitch, at least tested before the end of the quarter. And frankly, yeah, I would love for the Sitewide analytics to be a part of that. I don't know exactly how I would do that today, in all honesty. I don't, I'm not familiar or comfortable enough with the Sitewide analytics themselves currently in order to do that. But could, yeah, that could be an opportunity for sure.

>>Craig Phillips	33:45
Sweet. All right. Maybe any, is there a final question for anybody? Any burning? I think we hit on most of the key points, but curious if there's any like burning thing just before we wrap up.

>>Kate White	33:58
I know we're at times, it just feels like, sorry, Hannah.

>>Hannah Patterson	34:03
No, go ahead.

>>Kate White	34:06
I was wondering like, I can make some assumptions based on the ease of use challenge, but I'm wondering if like while you were demoing, there are any like cringy moments where every time you're like, oh c***, here's this part of the demo, or like, they're gonna ask a million questions on this section, anything along those lines?

>>Emily Brown	34:24
Yeah. And maybe about a month ago, we had Sam and Nate join a sales stand and the sales team delivered, like we had this exact conversation and Sam took like a bunch of notes. And I think she's like working on revamping the sales demo environment. So I would think with her as well,

>>Emily Brown	34:48
As well, but stuff like the onsite editor, you never know when that thing's gonna load, when it's not gonna load. Shipping testing, you really can't. Previously, there was like this idea where like, if there was one shipping test created, then you couldn't create another. So our way of demoing it was like showing one that was already created. And like, I think that has been solved for. There were literally pieces of the shipping test creation workflow that I saw for the first time ever, like last month, because they had just been like, not accessible in the sales demo environment where we weren't accessing it the right way. So there's like those like tactical pieces. And also thematically, one of the ideas that came up was really building customer success stories into the workflow for demoing particular features and functionality, where like, we were kind of doing this before, but it wasn't, or they were there, but it wasn't really enabled. So as an example, like in the test library, there were like the demo experiments that we would show, especially for analytics, like they would have like a customer name associated with it, and maybe at one point in time, the team was aware of the particular story behind those experiments, but like that didn't really, that doesn't exist today, it didn't transfer to the current team, I guess.

>>Emily Brown	36:29
So like one of the things that we thought about was using as realistic and real examples as possible for the various different test types and experience types, tying them to particular customers and their like real life success stories, and then enabling the team to tell those stories and not just say, hey, here's how you run a price test, content test, or whatever, but like, hey, here's an example of this brand that wanted to sell for this thing, and they used the test type you have in mind to run this exact experiment, here's how they did it and the results that they had. What if those tests existed out of the box? Yeah, And yeah, and then to be able to say, also, if you want to run this exact test yourself, here it is for you, dope, right? Like, cool, what are brands doing today? What are the winning tests? They're right here.

>>Craig Phillips	37:40
Great, all right. Hannah, I know we're like, we're running out of time, Hannah, you were about to say something, was there a little more that you?

>>Hannah Patterson	37:48
I was just curious on the competitors, probably like particularly Shoplift, if there's specific things people are saying are simpler, or if it's just like a general idea that that platform as a whole is simpler.

>>Emily Brown	38:03
The simplicity piece, I mean, the ease of use, I hear more from visually. For Shoplift, more often than not, it is my experience has been feeling like customers more so go to, historically, they've gone to them more using the excuse of like the low -hanging fruit situation, where they're like, I get that I can do more with intelligence, I know it's more sophisticated, X, Y, Z, but we literally just have the easiest, most simple experiments in mind to start with, so we're gonna start there, and then if this testing program shows success and continues to grow within our business, we could see ourselves using intelligence in the future kind of a thing, which does bring up another idea, not just in the sense that some brands are at the beginning of their testing journey, but there are also organizations that, like Wreath was a really good example of this, where there's two sales that need to happen. Sale number one is, do you agree that testing is important or not? Do you even wanna test at all? Do you see the value in testing at all?

>>Emily Brown	39:44
And then sale number two is assuming you do, great, now what's next?

>>Emily Brown	39:47
What's the best way to do it, intelligence, whatever. There are a certain segment of prospects that we talk to that haven't been, the organization has not been sold on the idea that testing is an important function that they should do in the business as a whole. So, and that is oftentimes when this idea of like, even a sophisticated customer, like Reef, when our, the director of e -com there, this guy, Brandon, when we first started talking to him earlier this year, he had been hired to build out the Cro program from scratch at Reef. So there was also like a little bit of risk reward and how far he wanted to stick his neck out for spending a bunch of money on a particular tool after he just got hired. But like, that was also his excuse was like, listen, I just got hired here. Like the team needs to get comfortable with the idea of testing and I just need to like show them some of the stuff that is possible. So I'm going to go with this like really lightweight, low cost tool and shoplift first build up the confidence of the team around experimentation and then get to you guys. Um, so that wasn't even like an, an ease of use thing that was more so just like looking at a lower cost option to tackle some really lightweight experiments first before getting to like this perceived next level of sophistication with intelligence.

>>Craig Phillips	41:22
Nice. Okay.

>>Emily Brown	41:26
And now they're back. They're f****** running price tests, shipping tests, like the whole shebang. And they used shoplift and Vwo in between coming back to us.

>>Craig Phillips	41:39
Well, interesting. Good.

>>Emily Brown	41:43
Okay. So we're, we're way over time.

>>Craig Phillips	41:44
So Matt, I think we'll let you go, but thank you so much for taking the time. I think a lot of this was really good stuff.

>>Emily Brown	41:52
Yeah.

>>Craig Phillips	41:53
Yeah. Really appreciate it. All right.

>>Emily Brown	41:56
Great.

>>Kate White	41:58
Later.